{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip uninstall stable-baselines3\n",
    "#%pip install stable-baselines3==1.7.0 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv, VecTransposeImage\n",
    "from matplotlib import pyplot as plt\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT,COMPLEX_MOVEMENT,RIGHT_ONLY\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEnvironments_DQN(env_name):\n",
    "    env = gym_super_mario_bros.make(env_name)\n",
    "    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "    env = GrayScaleObservation(env, keep_dim=True)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecFrameStack(env,4,channels_order='last')\n",
    "    env = VecTransposeImage(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEnvironment_PPO(env_name):\n",
    "        env = gym_super_mario_bros.make(env_name)\n",
    "        env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "        env = GrayScaleObservation(env, keep_dim=True)\n",
    "        return env\n",
    "    \n",
    "def allWorldStages():\n",
    "    worlds = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    #Training on Stages 1-3 for each world, testing on final stage of each world\n",
    "    stages = [4]\n",
    "\n",
    "    for world in worlds:\n",
    "        for stage in stages:\n",
    "            environment_name = f\"SuperMarioBros-{world}-{stage}-v0\"\n",
    "            yield environment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicho\\anaconda3\\envs\\aci\\lib\\site-packages\\gym\\envs\\registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-8-4-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\nicho\\anaconda3\\envs\\aci\\lib\\site-packages\\gym\\core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\nicho\\anaconda3\\envs\\aci\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env_names = [name for name in allWorldStages()]\n",
    "env_names = [1,2,3,4,5,6,7,8,9,10]\n",
    "#print(env_names)\n",
    "\n",
    "env = DummyVecEnv([lambda env_name=name: createEnvironment_PPO(\"SuperMarioBros-8-4-v0\") for name in env_names])\n",
    "env = VecTransposeImage(env)\n",
    "\n",
    "observation_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "model = PPO.load(\"./train/FinalModels/PPO_10\",env,custom_objects={'observation_space': observation_space, 'action_space': action_space})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "episode_reward = 0\n",
    "episode_score = 0\n",
    "episode_global_dist = 0\n",
    "cum_reward = 0\n",
    "count =0\n",
    "while count <= 100:\n",
    "    episode_global_dist = 0\n",
    "    action, _state, = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    episode_reward =+ reward\n",
    "    game_info = info[0]\n",
    "    episode_score =+ game_info['score']\n",
    "    episode_dist =+ game_info['x_pos']\n",
    "    if episode_dist is not None:       \n",
    "        episode_furthest_distance = max(episode_global_dist, episode_dist)\n",
    "        episode_global_dist = max(episode_global_dist, episode_dist)\n",
    "    cum_reward += reward\n",
    "    if any(done):\n",
    "        count = count + 1\n",
    "        print(\"Episode\" , count)\n",
    "        print(\"Cumulative Reward\" , cum_reward)\n",
    "        print(f\"Reward {episode_reward}. Score {episode_score}. Distance {episode_global_dist}\")\n",
    "        #print(f\"Episode furthest distance:{episode_furthest_distance}. Episode global distance {episode_global_dist}\")\n",
    "    env.render()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
