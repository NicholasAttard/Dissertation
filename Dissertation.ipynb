{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["v9QwVNGGaJKB","82hAqorraS0Q","cOrPZfrtF4Us","-PbD_-04bso3","QwpaIDPRn1qd","51ths2gJp_bb","5vZAot1IcAJ4","FIbKroXnb8oq"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Setting Up Packages and Game Environment"],"metadata":{"id":"v9QwVNGGaJKB"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmN9Aqa1YMAi","executionInfo":{"status":"ok","timestamp":1716479148371,"user_tz":-120,"elapsed":10296,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"outputId":"3db51215-3529-4da5-8f33-a9f7e221045a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (0.0.8)\n"]}],"source":["!pip install gym==0.25.2"]},{"cell_type":"code","source":["!pip install gym-super-mario-bros==7.3.0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJScdWtPZmZE","executionInfo":{"status":"ok","timestamp":1716479169113,"user_tz":-120,"elapsed":20747,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"outputId":"6a30e497-8509-4f77-a8c8-b6d040a70bf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gym-super-mario-bros==7.3.0\n","  Downloading gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nes-py>=8.0.0 (from gym-super-mario-bros==7.3.0)\n","  Downloading nes_py-8.2.1.tar.gz (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.25.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.25.2)\n","Collecting pyglet<=1.5.21,>=1.4.0 (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0)\n","  Downloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (4.66.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.0.8)\n","Building wheels for collected packages: nes-py\n","  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nes-py: filename=nes_py-8.2.1-cp310-cp310-linux_x86_64.whl size=535722 sha256=64750e8f210ceda374064dd4f7b3647fe81970e96d2b16c9a6905c2de2f7e154\n","  Stored in directory: /root/.cache/pip/wheels/34/a7/d5/9aa14b15df740a53d41f702e4c795731b6c4da7925deb8476c\n","Successfully built nes-py\n","Installing collected packages: pyglet, nes-py, gym-super-mario-bros\n","Successfully installed gym-super-mario-bros-7.3.0 nes-py-8.2.1 pyglet-1.5.21\n"]}]},{"cell_type":"code","source":["!pip install nes-py==8.2.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krkhRy8oZmBV","executionInfo":{"status":"ok","timestamp":1716479174538,"user_tz":-120,"elapsed":5436,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"outputId":"242731d5-1133-499c-96f8-d6cda43e8efa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nes-py==8.2.1 in /usr/local/lib/python3.10/dist-packages (8.2.1)\n","Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes-py==8.2.1) (0.25.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes-py==8.2.1) (1.25.2)\n","Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nes-py==8.2.1) (1.5.21)\n","Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py==8.2.1) (4.66.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py==8.2.1) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py==8.2.1) (0.0.8)\n"]}]},{"cell_type":"code","source":["# Import the game\n","import gym_super_mario_bros\n","# Import the Joypad wrapper\n","from nes_py.wrappers import JoypadSpace\n","# Import the SIMPLIFIED controls\n","from gym_super_mario_bros.actions import SIMPLE_MOVEMENT,COMPLEX_MOVEMENT,RIGHT_ONLY"],"metadata":{"id":"IRMDz4D8Z4Sd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup game\n","#env = gym_super_mario_bros.make('SuperMarioBros-v1')\n","#env = JoypadSpace(env, SIMPLE_MOVEMENT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zihnlTJJZ7wt","executionInfo":{"status":"ok","timestamp":1716479175257,"user_tz":-120,"elapsed":5,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"outputId":"f51371bd-9909-4512-e582-ffc832ae2a52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","source":["#Simplifies movements\n","#print(SIMPLE_MOVEMENT)\n","#print(COMPLEX_MOVEMENT)\n","#print(RIGHT_ONLY)\n","\n","#With env = JoypadSpace(env, SIMPLE_MOVEMENT) 256 action space\n","#Simple movement 7 action space\n","#Allows environment to be easier\n","#env.action_space"],"metadata":{"id":"399-8JwDZ-Rf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Single frame of 240 pixels by 256 pixels with 3 color range (RBG)\n","#env.observation_space.shape"],"metadata":{"id":"xGxsD7IdaAWX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Performs random action from action space\n","#SIMPLE_MOVEMENT[env.action_space.sample()]"],"metadata":{"id":"K33NAqNWaCJb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import matplotlib.pyplot as plt\n","#plt.switch_backend('agg')"],"metadata":{"id":"8NKc8qEYgurj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a flag - restart or not\n","#done = True\n","# Loop through each frame in the game\n","#for step in range(1000):\n","    # Start the game to begin with\n"," #   if done:\n","        # Start the game\n","#        env.reset()\n","    # Do random actions\n","#    state, reward, done, info = env.step(env.action_space.sample())\n","    # Show the game on the screen\n","    #env.render()\n","# Close the game\n","#env.close()"],"metadata":{"id":"Bb_0Q6yyaD4I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#If the environment stops but keeps running\n","#env.close()"],"metadata":{"id":"l-3iBooHaFeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#env.reset()\n","#returns State\n","#print(env.step(1)[0])\n","\n","#returns Reward\n","#print(env.step(1)[1])\n","\n","#returns game state as bool\n","#print(env.step(1)[2])\n","\n","#returns info about game\n","#print(env.step(1)[3])"],"metadata":{"id":"j1eLjggKaHQw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"82hAqorraS0Q"}},{"cell_type":"code","source":["!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 -f https://download.pytorch.org/whl/cu113/torch_stable.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0i-iY_scaXEG","executionInfo":{"status":"ok","timestamp":1716479296882,"user_tz":-120,"elapsed":121627,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"outputId":"26ddd3b8-de74-45af-ff4a-bba06fc90842"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n","Collecting torch==1.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m828.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.12.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (22.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==0.11.0\n","  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu113) (4.11.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (9.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2024.2.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.18.0+cu121\n","    Uninstalling torchvision-0.18.0+cu121:\n","      Successfully uninstalled torchvision-0.18.0+cu121\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.3.0+cu121\n","    Uninstalling torchaudio-2.3.0+cu121:\n","      Successfully uninstalled torchaudio-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n"]}]},{"cell_type":"code","source":["#!pip install stable-baselines3==1.2.0\n","!pip install stable-baselines3==1.7.0 --no-deps"],"metadata":{"id":"vV_VS_EGaffN","executionInfo":{"status":"ok","timestamp":1716479297785,"user_tz":-120,"elapsed":915,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b387a4f-15a9-4149-f170-5489eb0de412"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stable-baselines3==1.7.0\n","  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/171.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m122.9/171.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: stable-baselines3\n","Successfully installed stable-baselines3-1.7.0\n"]}]},{"cell_type":"code","source":["#Check stablebaseline version\n","import stable_baselines3\n","\n","print(stable_baselines3.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Syb1rwTkazzZ","executionInfo":{"status":"ok","timestamp":1716479299318,"user_tz":-120,"elapsed":1534,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"outputId":"8f797e5b-4b7c-44ef-bfb0-5963797c7ca0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n","  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"]},{"output_type":"stream","name":"stdout","text":["1.7.0\n"]}]},{"cell_type":"code","source":["#Wrappers to frame stack and convert to greyscale\n","from gym.wrappers import GrayScaleObservation\n","#Vectorisation Wrappers\n","from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n","from stable_baselines3.common.vec_env import VecTransposeImage\n","#Matplotlib to see frame stacking\n","from matplotlib import pyplot as plt"],"metadata":{"id":"j4jmQKuwa59r","executionInfo":{"status":"ok","timestamp":1716479299319,"user_tz":-120,"elapsed":7,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"99a804b9-e411-4c81-cd4b-d7456b32e265"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"markdown","source":["### Environment & Stage Functions"],"metadata":{"id":"cOrPZfrtF4Us"}},{"cell_type":"code","source":["def allWorldStages():\n","    worlds = [1, 2, 3, 4, 5, 6, 7, 8]\n","    #Training on Stages 1-3 for each world, testing on final stage of each world\n","    stages = [1, 2, 3]\n","\n","    for world in worlds:\n","        for stage in stages:\n","            environment_name = f\"SuperMarioBros-{world}-{stage}-v0\"\n","            yield environment_name"],"metadata":{"id":"PjQbNdJZmrTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_env(env_name):\n","    env = gym_super_mario_bros.make(env_name)\n","    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n","    env = GrayScaleObservation(env, keep_dim=True)\n","    env = VecTransposeImage(env)\n","    return env"],"metadata":{"id":"2x78PO9psgGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def createEnvironments_DQN(env_name):\n","    env = gym_super_mario_bros.make(env_name)\n","    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n","    env = GrayScaleObservation(env, keep_dim=True)\n","    env = DummyVecEnv([lambda: env])\n","    env = VecFrameStack(env,4,channels_order='last')\n","    env = VecTransposeImage(env)\n","    return env"],"metadata":{"id":"Jy05DejJQw9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def createEnvironment_PPO(env_name):\n","        env = gym_super_mario_bros.make(env_name)\n","        env = JoypadSpace(env, SIMPLE_MOVEMENT)\n","        env = GrayScaleObservation(env, keep_dim=True)\n","        return env"],"metadata":{"id":"OAnhKgqopDEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env_names = [name for name in allWorldStages()]\n","print(env_names)"],"metadata":{"id":"EDdQaK0oT7g3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716479299320,"user_tz":-120,"elapsed":6,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"outputId":"dedaf76c-3c07-42b8-b766-dc06e33fe780"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['SuperMarioBros-1-1-v0', 'SuperMarioBros-1-2-v0', 'SuperMarioBros-1-3-v0', 'SuperMarioBros-2-1-v0', 'SuperMarioBros-2-2-v0', 'SuperMarioBros-2-3-v0', 'SuperMarioBros-3-1-v0', 'SuperMarioBros-3-2-v0', 'SuperMarioBros-3-3-v0', 'SuperMarioBros-4-1-v0', 'SuperMarioBros-4-2-v0', 'SuperMarioBros-4-3-v0', 'SuperMarioBros-5-1-v0', 'SuperMarioBros-5-2-v0', 'SuperMarioBros-5-3-v0', 'SuperMarioBros-6-1-v0', 'SuperMarioBros-6-2-v0', 'SuperMarioBros-6-3-v0', 'SuperMarioBros-7-1-v0', 'SuperMarioBros-7-2-v0', 'SuperMarioBros-7-3-v0', 'SuperMarioBros-8-1-v0', 'SuperMarioBros-8-2-v0', 'SuperMarioBros-8-3-v0']\n"]}]},{"cell_type":"markdown","source":["### Callback function & Directories"],"metadata":{"id":"-PbD_-04bso3"}},{"cell_type":"code","source":["#Import Os for file path management\n","import os\n","\n","#Import PPO for algos\n","from stable_baselines3 import PPO\n","from stable_baselines3 import DQN\n","\n","#Import base callback for saving models\n","from stable_baselines3.common.callbacks import BaseCallback\n","import torch"],"metadata":{"id":"UwCN0PJlbvyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","folder_path = '/content/drive/MyDrive/DissertationModels'\n","os.chdir(folder_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuF12XdcebYq","executionInfo":{"status":"ok","timestamp":1716479327890,"user_tz":-120,"elapsed":28575,"user":{"displayName":"Nicholas Attard","userId":"05800430776324948968"}},"outputId":"7a457b04-7820-4414-c7b0-4de94edb4135"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["class TrainAndLoggingCallback(BaseCallback):\n","\n","    def __init__(self, check_freq, save_path, verbose=1):\n","        super(TrainAndLoggingCallback, self).__init__(verbose)\n","        self.check_freq = check_freq\n","        self.save_path = save_path\n","\n","    def _init_callback(self):\n","        if self.save_path is not None:\n","            os.makedirs(self.save_path, exist_ok=True)\n","\n","    def _on_step(self):\n","        if self.n_calls % self.check_freq == 0:\n","            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n","            self.model.save(model_path)\n","            try:\n","                self.model.save(model_path)\n","                print(f\"Model saved at iteration {self.n_calls} to {model_path}\")\n","            except Exception as e:\n","                print(f\"Error saving model at iteration {self.n_calls}: {e}\")\n","\n","        return True\n","\n","    def get_num_episodes(self):\n","        return self.num_episodes"],"metadata":{"id":"e8gUKd96b0Z7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CHECKPOINT_DIR_PPO = './trainPPO'\n","CHECKPOINT_DIR_DQN = './trainDQN'\n","LOG_DIR = './logs'"],"metadata":{"id":"pqvkrm5Qb2Xb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbackPPO = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR_PPO)\n","callbackDQN = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR_DQN)"],"metadata":{"id":"u3e8igTIb4O3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Initialisation"],"metadata":{"id":"QwpaIDPRn1qd"}},{"cell_type":"code","source":["#Environment Creation for PPO\n","env_names = [name for name in allWorldStages()]\n","print(env_names)\n","\n","env = DummyVecEnv([lambda env_name=name: createEnvironment_PPO(env_name) for name in env_names])\n","env = VecTransposeImage(env)"],"metadata":{"id":"X19Dexu_nufG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = PPO('CnnPolicy',env,verbose=1,tensorboard_log=LOG_DIR,learning_rate=0.00001,n_steps=512,batch_size=64,gamma=0.6)"],"metadata":{"id":"m-9x_iW7b6rQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#For PPO since the environments are all in 1, 250,000 timesteps is used to give each env 10,000 frames. Extra frames for saving purposes.\n","model.learn(total_timesteps=500000,callback=callbackPPO)"],"metadata":{"id":"Ti-iWT00b8jR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelDQN = DQN('CnnPolicy',createEnvironments_DQN(env_names[0]),verbose=1,tensorboard_log=LOG_DIR,learning_rate=0.00001,buffer_size=10000,batch_size=64,gamma=0.6)"],"metadata":{"id":"skThfYB1n9mD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for env_name in env_names:\n","    env = createEnvironments_DQN(env_name)\n","    modelDQN.set_env(env)\n","    print(f\"Model Env Updated to {env_name}\")\n","    modelDQN.learn(total_timesteps=10000,callback=callbackDQN)\n","    env.close()"],"metadata":{"id":"0A430c8XpFVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#env = DummyVecEnv([lambda env_name=name: make_env(env_name) for name in env_names])\n","#env = VecFrameStack(env, 4, channels_order='last')\n","#env = VecTransposeImage(env)\n","observation_space = env.observation_space\n","action_space = env.action_space\n","model = PPO.load(CHECKPOINT_DIR_PPO+\"/best_model_20000\",env,custom_objects={'observation_space': observation_space, 'action_space': action_space})\n","model.learn(total_timesteps=250000, callback=callbackPPO)"],"metadata":{"id":"AcLC4k-JoDHB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading Models to Continue Training"],"metadata":{"id":"51ths2gJp_bb"}},{"cell_type":"code","source":["observation_space = env.observation_space\n","action_space = env.action_space\n","model = PPO.load('/content/drive/MyDrive/DissertationModels/trainPPO/best_model_10000', env,custom_objects={'observation_space': observation_space, 'action_space': action_space})\n","model.learn(total_timesteps=10000, callback=callback)"],"metadata":{"id":"rnD3rTMLX2Lt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","env=createEnvironments_DQN(env_names[0])\n","observation_space = env.observation_space\n","action_space = env.action_space\n","device = torch.device('cuda')\n","model = DQN.load(\"/content/drive/MyDrive/DissertationModels/trainDQN/best_model_630000\",createEnvironments_DQN(env_names[0]),device=device,custom_objects={'observation_space': observation_space, 'action_space': action_space})\n","for env_name in env_names:\n","    env = createEnvironments_DQN(env_name)\n","    model.set_env(env)\n","    print(f\"Model Env Updated to {env_name}\")\n","    model.learn(total_timesteps=80000, callback=callbackDQN)\n","    env.close()"],"metadata":{"id":"IUhOmmpmosQJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Testing"],"metadata":{"id":"5vZAot1IcAJ4"}},{"cell_type":"code","source":["!pip install opencv-python-headless"],"metadata":{"id":"oXCYk8YnRpaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env=createEnvironments_DQN(env_names[0])\n","observation_space = env.observation_space\n","action_space = env.action_space\n","device = torch.device('cuda')\n","\n","model = DQN.load('./trainedModels/DQN1/best_model_720000',env,custom_objects={'observation_space': observation_space, 'action_space': action_space})\n","\n","##Get cumulative score, distance traveled and cumulative reward while training with training and testing env to check which is training better in know env and which is more adaptive"],"metadata":{"id":"EmFcRL50cC2n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_episodes(model, env, num_episodes=100):\n","    cumulative_rewards = []\n","    steps_per_episode = []\n","    for episode in range(num_episodes):\n","        obs = env.reset()\n","        episode_reward = 0\n","        steps = 0\n","        done = [False] * env.num_envs  # Initialize done for each environment\n","        while not any(done):\n","            action, _ = model.predict(obs, deterministic=True)\n","            obs, reward, done, _ = env.step(action)\n","            episode_reward += reward\n","            steps += 1\n","        cumulative_rewards.append(episode_reward)\n","        steps_per_episode.append(steps)\n","        print(f\"Episode {episode + 1}, Cumulative Reward: {episode_reward}, Steps: {steps}\")\n","    return cumulative_rewards, steps_per_episode\n","\n","num_episodes = 100\n","cumulative_rewards, steps_per_episode = run_episodes(model, env, num_episodes)\n","\n","total_reward = sum(cumulative_rewards)\n","\n","print(\"Cumulative Rewards:\", cumulative_rewards)\n","print(\"Total Reward:\", total_reward)\n","print(\"Steps per Episode:\", steps_per_episode)\n"],"metadata":{"id":"zWgso-OCPebc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def get_cumulative_score(env, model, num_episodes=100):\n","    total_score = 0\n","    for episode in range(1, num_episodes + 1):\n","        obs = env.reset()\n","        episode_score = 0\n","        done = np.array([False] * env.num_envs)  # Initialize done as an array\n","        while not any(done):\n","            action, _ = model.predict(obs, deterministic=True)\n","            obs, reward, done, info = env.step(action)\n","            game_info = info[0]\n","            episode_score += game_info['score']\n","        total_score += episode_score\n","        print(f\"Episode {episode}, Cumulative Score: {episode_score}\")\n","    return total_score\n","\n","cumulative_score = get_cumulative_score(env, model, num_episodes=100)\n","print(\"Cumulative Score:\", cumulative_score)"],"metadata":{"id":"0p2PvkGtQne6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_furthest_distance(env, model, num_episodes=100):\n","    global_furthest_distance = 0\n","    for episode in range(1, num_episodes + 1):\n","        obs = env.reset()\n","        prev_position = None\n","        episode_furthest_distance = 0\n","        done = np.array([False] * env.num_envs)  # Initialize done as an array\n","        while not any(done):\n","            action, _ = model.predict(obs, deterministic=True)\n","            obs, reward, done, info_list = env.step(action)\n","            game_info = info_list[0]\n","            x_position = game_info['x_pos']\n","            if x_position is not None:\n","                episode_furthest_distance = max(episode_furthest_distance, x_position)\n","                global_furthest_distance = max(global_furthest_distance, x_position)\n","        print(f\"Episode {episode}, Distance Traveled: {episode_furthest_distance}, Furthest Distance: {global_furthest_distance}\")\n","    return global_furthest_distance\n","\n","furthest_distance = get_furthest_distance(env, model, num_episodes=100)\n","print(\"Furthest Distance Traveled:\", furthest_distance)"],"metadata":{"id":"z-9RsZlASRtY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"QU6r9_iU38hB"}},{"cell_type":"markdown","source":["### Extra"],"metadata":{"id":"FIbKroXnb8oq"}},{"cell_type":"code","source":["import time\n","\n","# Set the time interval for re-running the cell (in seconds)\n","interval_seconds = 5  # Adjust this as needed\n","\n","# Set the maximum number of runs\n","max_runs = 3\n","\n","# Initialize the counter\n","run_count = 0\n","\n","while run_count < max_runs:\n","    # Increment the run count\n","    run_count += 1\n","\n","    # Your code goes here\n","    print(\"Run\", run_count, \"- This cell will re-run every {} seconds.\".format(interval_seconds))\n","\n","    # Sleep for the specified interval\n","    time.sleep(interval_seconds)\n","\n","print(\"Reached maximum number of runs. Exiting the loop.\")\n"],"metadata":{"id":"tAiwVurSRGzY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env = gym_super_mario_bros.make('SuperMarioBros-1-1-v1')\n","env = JoypadSpace(env, SIMPLE_MOVEMENT)\n","env = GrayScaleObservation(env, keep_dim=True)\n","env = DummyVecEnv([lambda: env])\n","env = VecFrameStack(env,4,channels_order='last')\n","\n","state = env.reset()\n","print(state.shape)\n","\n","model = PPO('CnnPolicy',env,verbose=1,tensorboard_log=LOG_DIR,learning_rate=0.000001,n_steps=256)\n","model.learn(total_timesteps=10000,callback=callbackPPO)"],"metadata":{"id":"EPpmBktBHiRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model= PPO('CnnPolicy',env,verbose=1,tensorboard_log=LOG_DIR,learning_rate=0.000001,n_steps=128)\n","model = PPO.load(CHECKPOINT_DIR_PPO+\"/best_model_10000.zip\")"],"metadata":{"id":"ruSztT1LxfmX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gym.wrappers import GrayScaleObservation\n","import stable_baselines3\n","from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n","from stable_baselines3.common.vec_env import VecTransposeImage\n","from matplotlib import pyplot as plt\n","import gym_super_mario_bros\n","from nes_py.wrappers import JoypadSpace\n","from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n","import os\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.callbacks import BaseCallback\n","\n","env = gym_super_mario_bros.make('SuperMarioBros-v0')\n","env = JoypadSpace(env, SIMPLE_MOVEMENT)\n","env = GrayScaleObservation(env, keep_dim=True)\n","env = DummyVecEnv([lambda: env])\n","env = VecFrameStack(env, 4, channels_order='last')\n","env = VecTransposeImage(env)\n","\n","class TrainAndLoggingCallback(BaseCallback):\n","\n","    def __init__(self, check_freq, save_path, verbose=1):\n","        super(TrainAndLoggingCallback, self).__init__(verbose)\n","        self.check_freq = check_freq\n","        self.save_path = save_path\n","\n","    def _init_callback(self):\n","        if self.save_path is not None:\n","            os.makedirs(self.save_path, exist_ok=True)\n","\n","    def _on_step(self):\n","        if self.n_calls % self.check_freq == 0:\n","            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n","            self.model.save(model_path)\n","\n","        return True\n","\n","CHECKPOINT_DIR = './train/'\n","LOG_DIR = './logs/'\n","\n","callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n","\n","os.chdir(folder_path)\n","\n","model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001,\n","            n_steps=512)\n","\n","model.learn(total_timesteps=10000, callback=callback)\n","observation_space = env.observation_space\n","action_space = env.action_space\n","\n","print(f\"Observation Space: {observation_space}, Env Observation Space: {env.observation_space}\")\n","print(f\"Action space {action_space}\")\n","\n","model = PPO.load('./train/best_model_10000', env,custom_objects={'observation_space': observation_space, 'action_space': action_space})\n","\n","model.learn(total_timesteps=10000, callback=callback)"],"metadata":{"id":"84pe-y6LSjpV"},"execution_count":null,"outputs":[]}]}